# YOLOv5 ğŸš€ by Ultralytics, GPL-3.0 license
"""
æœåŠ¡äºwinæ¡Œé¢åº”ç”¨çš„è¯†åˆ«æœåŠ¡ç¨‹åº
"""

import os
import platform
import sys
from pathlib import Path

import torch

FILE = Path(__file__).resolve()
ROOT = FILE.parents[0]  # YOLOv5 root directory
if str(ROOT) not in sys.path:
    sys.path.append(str(ROOT))  # add ROOT to PATH
ROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relative

from models.common import DetectMultiBackend
from utils.dataloaders import IMG_FORMATS, VID_FORMATS, LoadImages, LoadScreenshots, LoadStreams
from utils.general import (LOGGER, Profile, check_file, check_img_size, check_imshow, check_requirements, colorstr, cv2,
                           increment_path, non_max_suppression, scale_boxes, strip_optimizer, xyxy2xywh)
from utils.plots import Annotator, colors, save_one_box
from utils.torch_utils import select_device, smart_inference_mode


@smart_inference_mode()  # ç”¨äºè‡ªåŠ¨åˆ‡æ¢æ¨¡å‹çš„æ¨ç†æ¨¡å¼ï¼Œå¦‚æœæ˜¯FP16æ¨¡å‹ï¼Œåˆ™è‡ªåŠ¨åˆ‡æ¢ä¸ºFP16æ¨ç†æ¨¡å¼ï¼Œå¦åˆ™åˆ‡æ¢ä¸ºFP32æ¨ç†æ¨¡å¼ï¼Œè¿™æ ·å¯ä»¥é¿å…æ¨¡å‹æ¨ç†æ—¶å‡ºç°ç±»å‹ä¸åŒ¹é…çš„é”™è¯¯
def run(
        weights=ROOT / 'yolov5s.pt',  # model path or triton URL
        source=ROOT / 'data/images',  # file/dir/URL/glob/screen/0(webcam)
        data=ROOT / 'data/coco128.yaml',  # dataset.yaml path
        imgsz=(640, 640),  # inference size (height, width)
        conf_thres=0.25,  # confidence threshold
        iou_thres=0.45,  # NMS IOU threshold
        max_det=1000,  # maximum detections per image
        device='',  # cuda device, i.e. 0 or 0,1,2,3 or cpu
        view_img=False,  # show results
        save_txt=False,  # save results to *.txt
        save_conf=False,  # save confidences in --save-txt labels
        save_crop=False,  # save cropped prediction boxes
        nosave=False,  # do not save images/videos
        classes=None,  # filter by class: --class 0, or --class 0 2 3
        agnostic_nms=False,  # class-agnostic NMS
        augment=False,  # augmented inference
        visualize=False,  # visualize features
        update=True,  # update all models
        project=ROOT / 'runs/detect',  # save results to project/name
        name='exp',  # save results to project/name
        exist_ok=False,  # existing project/name ok, do not increment
        line_thickness=6,  # bounding box thickness (pixels)
        hide_labels=False,  # hide labels
        hide_conf=False,  # hide confidences
        half=False,  # use FP16 half-precision inference
        dnn=False,  # use OpenCV DNN for ONNX inference
        vid_stride=1,  # video frame-rate stride
):
    #################################################################åˆå§‹åŒ–å‚æ•°#################################################################
    source = str(source)  # å°†sourceè½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œsourceä¸ºè¾“å…¥çš„å›¾ç‰‡ã€è§†é¢‘ã€æ‘„åƒå¤´ç­‰
    save_img = not nosave and not source.endswith('.txt')  # åˆ¤æ–­æ˜¯å¦ä¿å­˜å›¾ç‰‡ï¼Œå¦‚æœnosaveä¸ºFalseï¼Œä¸”sourceä¸æ˜¯txtæ–‡ä»¶ï¼Œåˆ™ä¿å­˜å›¾ç‰‡
    is_file = Path(source).suffix[1:] in (
            IMG_FORMATS + VID_FORMATS)  # åˆ¤æ–­sourceæ˜¯å¦æ˜¯æ–‡ä»¶.Path(source)ä½¿ç”¨sourceåˆ›å»ºä¸€ä¸ªPathå¯¹è±¡ï¼Œç”¨äºè·å–è¾“å…¥æºä¿¡æ¯ï¼Œsuffixè·å–æ–‡ä»¶æ‰©å±•åï¼š.jpg,.mp4ç­‰ï¼Œsuffix[1:]è·å–æ–‡ä»¶åç¼€ï¼Œåˆ¤æ–­åç¼€æ˜¯å¦åœ¨IMG_FORMATSå’ŒVID_FORMATSä¸­ï¼Œå¦‚æœæ˜¯ï¼Œåˆ™is_fileä¸ºTrue
    is_url = source.lower().startswith(('rtsp://', 'rtmp://', 'http://',
                                        'https://'))  # åˆ¤æ–­sourceæ˜¯å¦æ˜¯urlï¼Œå¦‚æœæ˜¯ï¼Œåˆ™is_urlä¸ºTrue.lower()å°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºå°å†™,startswith()åˆ¤æ–­å­—ç¬¦ä¸²æ˜¯å¦ä»¥æŒ‡å®šçš„å­—ç¬¦ä¸²å¼€å¤´
    webcam = source.isnumeric() or source.endswith('.streams') or (
            is_url and not is_file)  # source.isnumeric()åˆ¤æ–­sourceæ˜¯å¦æ˜¯æ•°å­—ï¼Œsource.endswith('.streams')åˆ¤æ–­sourceæ˜¯å¦ä»¥.streamsç»“å°¾ï¼Œ(is_url and not is_file)åˆ¤æ–­sourceæ˜¯å¦æ˜¯urlï¼Œä¸”ä¸æ˜¯æ–‡ä»¶ï¼Œä¸Šè¿°ä¸‰ä¸ªæ¡ä»¶æœ‰ä¸€ä¸ªä¸ºTrueï¼Œåˆ™webcamä¸ºTrueã€‚
    screenshot = source.lower().startswith('screen')  # åˆ¤æ–­sourceæ˜¯å¦æ˜¯æˆªå›¾ï¼Œå¦‚æœæ˜¯ï¼Œåˆ™screenshotä¸ºTrue
    if is_url and is_file:
        source = check_file(source)  # ç¡®ä¿è¾“å…¥æºä¸ºæœ¬åœ°æ–‡ä»¶ï¼Œå¦‚æœæ˜¯urlï¼Œåˆ™ä¸‹è½½åˆ°æœ¬åœ°ï¼Œcheck_file()å‡½æ•°ç”¨äºä¸‹è½½urlæ–‡ä»¶

    # Directoriesï¼Œåˆ›å»ºä¿å­˜ç»“æœçš„æ–‡ä»¶å¤¹
    save_dir = increment_path(Path(project) / name,
                              exist_ok=exist_ok)  # increment runï¼Œå¢åŠ æ–‡ä»¶æˆ–ç›®å½•è·¯å¾„ï¼Œå³è¿è¡Œ/expâ€”â€”>è¿è¡Œ/exp{sep}2ï¼Œè¿è¡Œ/exp{sep}3ï¼Œâ€¦ç­‰ã€‚exist_okä¸ºTrueæ—¶ï¼Œå¦‚æœæ–‡ä»¶å¤¹å·²å­˜åœ¨ï¼Œåˆ™ä¸ä¼šæŠ¥é”™
    (save_dir / 'labels' if save_txt else save_dir).mkdir(parents=True,
                                                          exist_ok=True)  # make dirï¼Œåˆ›å»ºæ–‡ä»¶å¤¹ï¼Œå¦‚æœsave_txtä¸ºTrueï¼Œåˆ™åˆ›å»ºlabelsæ–‡ä»¶å¤¹ï¼Œå¦åˆ™åˆ›å»ºsave_diræ–‡ä»¶å¤¹

    # Load model,åˆå§‹åŒ–æ¨¡å‹
    device = select_device(device)  # é€‰æ‹©è®¾å¤‡ï¼Œå¦‚æœdeviceä¸ºç©ºï¼Œåˆ™è‡ªåŠ¨é€‰æ‹©è®¾å¤‡
    model = DetectMultiBackend(weights, device=device, dnn=dnn, data=data,
                               fp16=half)  # åŠ è½½æ¨¡å‹ï¼ŒDetectMultiBackend()å‡½æ•°ç”¨äºåŠ è½½æ¨¡å‹ï¼Œweightsä¸ºæ¨¡å‹è·¯å¾„ï¼Œdeviceä¸ºè®¾å¤‡ï¼Œdnnä¸ºæ˜¯å¦ä½¿ç”¨opencv dnnï¼Œdataä¸ºæ•°æ®é›†ï¼Œfp16ä¸ºæ˜¯å¦ä½¿ç”¨fp16æ¨ç†
    stride, names, pt = model.stride, model.names, model.pt  # è·å–æ¨¡å‹çš„strideï¼Œnamesï¼Œpt,model.strideä¸ºæ¨¡å‹çš„strideï¼Œmodel.namesä¸ºæ¨¡å‹çš„ç±»åˆ«ï¼Œmodel.ptä¸ºæ¨¡å‹çš„ç±»å‹
    imgsz = check_img_size(imgsz, s=stride)  # check image size,éªŒè¯å›¾åƒå¤§å°æ˜¯æ¯ä¸ªç»´åº¦çš„stride=32çš„å€æ•°

    # Dataloader,åˆå§‹åŒ–æ•°æ®é›†
    bs = 1  # batch_size,åˆå§‹åŒ–batch_sizeä¸º1
    if webcam:  # å¦‚æœsourceæ˜¯æ‘„åƒå¤´ï¼Œåˆ™åˆ›å»ºLoadStreams()å¯¹è±¡
        view_img = check_imshow(warn=True)  # æ˜¯å¦æ˜¾ç¤ºå›¾ç‰‡ï¼Œå¦‚æœview_imgä¸ºTrueï¼Œåˆ™æ˜¾ç¤ºå›¾ç‰‡
        dataset = LoadStreams(source, img_size=imgsz, stride=stride, auto=pt,
                              vid_stride=vid_stride)  # åˆ›å»ºLoadStreams()å¯¹è±¡ï¼Œsourceä¸ºè¾“å…¥æºï¼Œimg_sizeä¸ºå›¾åƒå¤§å°ï¼Œstrideä¸ºæ¨¡å‹çš„strideï¼Œautoä¸ºæ˜¯å¦è‡ªåŠ¨é€‰æ‹©è®¾å¤‡ï¼Œvid_strideä¸ºè§†é¢‘å¸§ç‡
        bs = len(dataset)  # batch_sizeä¸ºæ•°æ®é›†çš„é•¿åº¦
    elif screenshot:  # å¦‚æœsourceæ˜¯æˆªå›¾ï¼Œåˆ™åˆ›å»ºLoadScreenshots()å¯¹è±¡
        dataset = LoadScreenshots(source, img_size=imgsz, stride=stride,
                                  auto=pt)  # åˆ›å»ºLoadScreenshots()å¯¹è±¡ï¼Œsourceä¸ºè¾“å…¥æºï¼Œimg_sizeä¸ºå›¾åƒå¤§å°ï¼Œstrideä¸ºæ¨¡å‹çš„strideï¼Œautoä¸ºæ˜¯å¦è‡ªåŠ¨é€‰æ‹©è®¾å¤‡
    else:
        dataset = LoadImages(source, img_size=imgsz, stride=stride, auto=pt,
                             vid_stride=vid_stride)  # åˆ›å»ºLoadImages()å¯¹è±¡ï¼Œç›´æ¥åŠ è½½å›¾ç‰‡ï¼Œsourceä¸ºè¾“å…¥æºï¼Œimg_sizeä¸ºå›¾åƒå¤§å°ï¼Œstrideä¸ºæ¨¡å‹çš„strideï¼Œautoä¸ºæ˜¯å¦è‡ªåŠ¨é€‰æ‹©è®¾å¤‡ï¼Œvid_strideä¸ºè§†é¢‘å¸§ç‡
    vid_path, vid_writer = [None] * bs, [None] * bs  # åˆå§‹åŒ–vid_pathå’Œvid_writerï¼Œvid_pathä¸ºè§†é¢‘è·¯å¾„ï¼Œvid_writerä¸ºè§†é¢‘å†™å…¥å¯¹è±¡

    #################################################################å¼€å§‹æ¨ç†#################################################################
    # Run inferenceï¼Œè¿è¡Œæ¨ç†
    model.warmup(imgsz=(1 if pt or model.triton else bs, 3,
                        *imgsz))  # warmupï¼Œé¢„çƒ­ï¼Œç”¨äºæå‰åŠ è½½æ¨¡å‹ï¼ŒåŠ å¿«æ¨ç†é€Ÿåº¦ï¼Œimgszä¸ºå›¾åƒå¤§å°ï¼Œå¦‚æœptä¸ºTrueæˆ–è€…model.tritonä¸ºTrueï¼Œåˆ™bs=1ï¼Œå¦åˆ™bsä¸ºæ•°æ®é›†çš„é•¿åº¦ã€‚3ä¸ºé€šé“æ•°ï¼Œ*imgszä¸ºå›¾åƒå¤§å°ï¼Œå³(1,3,640,640)
    seen, windows, dt = 0, [], (
        Profile(), Profile(), Profile())  # åˆå§‹åŒ–seenï¼Œwindowsï¼Œdtï¼Œseenä¸ºå·²æ£€æµ‹çš„å›¾ç‰‡æ•°é‡ï¼Œwindowsä¸ºç©ºåˆ—è¡¨ï¼Œdtä¸ºæ—¶é—´ç»Ÿè®¡å¯¹è±¡
    for path, im, im0s, vid_cap, s in dataset:  # éå†æ•°æ®é›†ï¼Œpathä¸ºå›¾ç‰‡è·¯å¾„ï¼Œimä¸ºå›¾ç‰‡ï¼Œim0sä¸ºåŸå§‹å›¾ç‰‡ï¼Œvid_capä¸ºè§†é¢‘è¯»å–å¯¹è±¡ï¼Œsä¸ºè§†é¢‘å¸§ç‡
        with dt[0]:  # å¼€å§‹è®¡æ—¶,è¯»å–å›¾ç‰‡
            im = torch.from_numpy(im).to(model.device)  # å°†å›¾ç‰‡è½¬æ¢ä¸ºtensorï¼Œå¹¶æ”¾åˆ°æ¨¡å‹çš„è®¾å¤‡ä¸Šï¼Œpytorchæ¨¡å‹çš„è¾“å…¥å¿…é¡»æ˜¯tensor
            im = im.half() if model.fp16 else im.float()  # uint8 to fp16/32    #å¦‚æœæ¨¡å‹ä½¿ç”¨fp16æ¨ç†ï¼Œåˆ™å°†å›¾ç‰‡è½¬æ¢ä¸ºfp16ï¼Œå¦åˆ™è½¬æ¢ä¸ºfp32
            im /= 255  # 0 - 255 to 0.0 - 1.0                         #å°†å›¾ç‰‡å½’ä¸€åŒ–ï¼Œå°†å›¾ç‰‡åƒç´ å€¼ä»0-255è½¬æ¢ä¸º0-1
            if len(im.shape) == 3:  # å¦‚æœå›¾ç‰‡çš„ç»´åº¦ä¸º3ï¼Œåˆ™æ·»åŠ batchç»´åº¦
                im = im[
                    None]  # expand for batch dim                 #åœ¨å‰é¢æ·»åŠ batchç»´åº¦ï¼Œå³å°†å›¾ç‰‡çš„ç»´åº¦ä»3ç»´è½¬æ¢ä¸º4ç»´ï¼Œå³(3,640,640)è½¬æ¢ä¸º(1,3,640,640)ï¼Œpytorchæ¨¡å‹çš„è¾“å…¥å¿…é¡»æ˜¯4ç»´çš„

        # Inference
        with dt[1]:  # å¼€å§‹è®¡æ—¶,æ¨ç†æ—¶é—´
            visualize = increment_path(save_dir / Path(path).stem,
                                       mkdir=True) if visualize else False  # å¦‚æœvisualizeä¸ºTrueï¼Œåˆ™åˆ›å»ºvisualizeæ–‡ä»¶å¤¹ï¼Œå¦åˆ™ä¸ºFalse
            pred = model(im, augment=augment,
                         visualize=visualize)  # æ¨ç†ï¼Œmodel()å‡½æ•°ç”¨äºæ¨ç†ï¼Œimä¸ºè¾“å…¥å›¾ç‰‡ï¼Œaugmentä¸ºæ˜¯å¦ä½¿ç”¨æ•°æ®å¢å¼ºï¼Œvisualizeä¸ºæ˜¯å¦å¯è§†åŒ–,è¾“å‡ºpredä¸ºä¸€ä¸ªåˆ—è¡¨ï¼Œå½¢çŠ¶ä¸ºï¼ˆn,6ï¼‰,nä»£è¡¨é¢„æµ‹æ¡†çš„æ•°é‡ï¼Œ6ä»£è¡¨é¢„æµ‹æ¡†çš„åæ ‡å’Œç½®ä¿¡åº¦ï¼Œç±»åˆ«

        # NMSï¼Œéæå¤§å€¼æŠ‘åˆ¶ï¼Œç”¨äºå»é™¤é‡å¤çš„é¢„æµ‹æ¡†
        with dt[2]:  # å¼€å§‹è®¡æ—¶,NMSæ—¶é—´
            pred = non_max_suppression(pred, conf_thres, iou_thres, classes, agnostic_nms,
                                       max_det=max_det)  # NMSï¼Œnon_max_suppression()å‡½æ•°ç”¨äºNMSï¼Œpredä¸ºè¾“å…¥çš„é¢„æµ‹æ¡†ï¼Œconf_thresä¸ºç½®ä¿¡åº¦é˜ˆå€¼ï¼Œiou_thresä¸ºioué˜ˆå€¼ï¼Œclassesä¸ºç±»åˆ«ï¼Œagnostic_nmsä¸ºæ˜¯å¦ä½¿ç”¨ç±»åˆ«æ— å…³çš„NMSï¼Œmax_detä¸ºæœ€å¤§æ£€æµ‹æ¡†æ•°é‡ï¼Œ

        # ç›´åˆ°è¿™ä¸€è¡Œï¼Œä¸Šé¢ğŸ‘†å±äºåŠ è½½å’Œæ¨ç†è¿‡ç¨‹ï¼Œä¸‹é¢ğŸ‘‡å‡å±äºäº‹ç‰©å¤„ç†è¿‡ç¨‹

        # Process predictions,å¤„ç†é¢„æµ‹ç»“æœ
        for i, det in enumerate(pred):  # per image,éå†æ¯å¼ å›¾ç‰‡,enumerate()å‡½æ•°å°†predè½¬æ¢ä¸ºç´¢å¼•å’Œå€¼çš„å½¢å¼ï¼Œiä¸ºç´¢å¼•ï¼Œdetä¸ºå¯¹åº”çš„å…ƒç´ ï¼Œå³æ¯ä¸ªç‰©ä½“çš„é¢„æµ‹æ¡†
            seen += 1  # æ£€æµ‹çš„å›¾ç‰‡æ•°é‡åŠ 1
            if webcam:  # batch_size >= 1ï¼Œå¦‚æœæ˜¯æ‘„åƒå¤´ï¼Œåˆ™è·å–è§†é¢‘å¸§ç‡
                p, im0, frame = path[i], im0s[
                    i].copy(), dataset.count  # path[i]ä¸ºè·¯å¾„åˆ—è¡¨ï¼Œims[i].copy()ä¸ºå°†è¾“å…¥å›¾åƒçš„å‰¯æœ¬å­˜å‚¨åœ¨im0å˜é‡ä¸­ï¼Œdataset.countä¸ºå½“å‰è¾“å…¥å›¾åƒçš„å¸§æ•°
                s += f'{i}: '  # åœ¨æ‰“å°è¾“å‡ºä¸­æ·»åŠ å½“å‰å¤„ç†çš„å›¾åƒç´¢å¼•å·iï¼Œæ–¹ä¾¿è°ƒè¯•å’ŒæŸ¥çœ‹ç»“æœã€‚åœ¨æ­¤å¤„ï¼Œå¦‚æœæ˜¯æ‘„åƒå¤´æ¨¡å¼ï¼Œiè¡¨ç¤ºå½“å‰æ‰¹æ¬¡ä¸­ç¬¬iå¼ å›¾åƒï¼›å¦åˆ™ï¼Œiå§‹ç»ˆä¸º0ï¼Œå› ä¸ºå¤„ç†çš„åªæœ‰ä¸€å¼ å›¾åƒã€‚
            else:
                p, im0, frame = path, im0s.copy(), getattr(dataset, 'frame', 0)  # å¦‚æœä¸æ˜¯æ‘„åƒå¤´ï¼Œframeä¸º0

            p = Path(p)  # to Path                             #å°†è·¯å¾„è½¬æ¢ä¸ºPathå¯¹è±¡
            save_path = str(save_dir / p.name)  # im.jpgï¼Œä¿å­˜å›¾ç‰‡çš„è·¯å¾„ï¼Œsave_dirä¸ºä¿å­˜å›¾ç‰‡çš„æ–‡ä»¶å¤¹ï¼Œp.nameä¸ºå›¾ç‰‡åç§°
            txt_path = str(save_dir / 'labels' / p.stem) + (
                '' if dataset.mode == 'image' else f'_{frame}')  # im.txtï¼Œä¿å­˜é¢„æµ‹æ¡†çš„è·¯å¾„ï¼Œsave_dirä¸ºä¿å­˜å›¾ç‰‡çš„æ–‡ä»¶å¤¹ï¼Œp.stemä¸ºå›¾ç‰‡åç§°ï¼Œdataset.modeä¸ºæ•°æ®é›†çš„æ¨¡å¼ï¼Œå¦‚æœæ˜¯imageï¼Œåˆ™ä¸ºå›¾ç‰‡ï¼Œå¦åˆ™ä¸ºè§†é¢‘
            s += '%gx%g ' % im.shape[2:]  # print string,æ‰“å°è¾“å‡ºï¼Œim.shape[2:]ä¸ºå›¾ç‰‡çš„å®½å’Œé«˜
            gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh,å½’ä¸€åŒ–å› å­ï¼Œç”¨äºå°†é¢„æµ‹æ¡†çš„åæ ‡ä»å½’ä¸€åŒ–åæ ‡è½¬æ¢ä¸ºåŸå§‹åæ ‡
            imc = im0.copy() if save_crop else im0  # for save_crop,å¦‚æœsave_cropä¸ºTrueï¼Œåˆ™å°†im0å¤åˆ¶ä¸€ä»½ï¼Œå¦åˆ™ä¸ºim0
            annotator = Annotator(im0, line_width=line_thickness,
                                  example=str(names))  # åˆ›å»ºAnnotatorå¯¹è±¡ï¼Œç”¨äºåœ¨å›¾ç‰‡ä¸Šç»˜åˆ¶é¢„æµ‹æ¡†å’Œæ ‡ç­¾,im0ä¸ºè¾“å…¥å›¾ç‰‡ï¼Œline_widthä¸ºçº¿å®½ï¼Œexampleä¸ºæ ‡ç­¾


            if len(det):  # å¦‚æœé¢„æµ‹æ¡†çš„æ•°é‡å¤§äº0

                # Rescale boxes from img_size to im0 size
                det[:, :4] = scale_boxes(im.shape[2:], det[:, :4],
                                         im0.shape).round()  # å°†é¢„æµ‹æ¡†çš„åæ ‡ä»å½’ä¸€åŒ–åæ ‡è½¬æ¢ä¸ºåŸå§‹åæ ‡,im.shape[2:]ä¸ºå›¾ç‰‡çš„å®½å’Œé«˜ï¼Œdet[:, :4]ä¸ºé¢„æµ‹æ¡†çš„åæ ‡ï¼Œim0.shapeä¸ºå›¾ç‰‡çš„å®½å’Œé«˜

                # Print results,æ‰“å°è¾“å‡º
                for c in det[:, 5].unique():  # éå†æ¯ä¸ªç±»åˆ«,unique()ç”¨äºè·å–æ£€æµ‹ç»“æœä¸­ä¸åŒç±»åˆ«æ˜¯æ•°é‡
                    n = (det[:, 5] == c).sum()  # detections per class                        #nä¸ºæ¯ä¸ªç±»åˆ«çš„é¢„æµ‹æ¡†çš„æ•°é‡
                    s += f"{n} {names[int(c)]}{'s' * (n > 1)}, "  # add to string             #sä¸ºæ¯ä¸ªç±»åˆ«çš„é¢„æµ‹æ¡†çš„æ•°é‡å’Œç±»åˆ«

                # Write resultsï¼Œå†™å…¥ç»“æœ
                the_pic_data = []  # å‡†å¤‡å±äºè¿™å¼ å›¾åƒçš„Listå®¹å™¨
                for *xyxy, conf, cls in reversed(det):  # éå†æ¯ä¸ªé¢„æµ‹æ¡†,xyxyä¸ºé¢„æµ‹æ¡†çš„åæ ‡ï¼Œconfä¸ºç½®ä¿¡åº¦ï¼Œclsä¸ºç±»åˆ«,reversed()å‡½æ•°ç”¨äºå°†åˆ—è¡¨åè½¬ï¼Œ*æ˜¯ä¸€ä¸ªæ‰©å±•è¯­æ³•ï¼Œ*xyxyè¡¨ç¤ºå°†xyxyä¸­çš„å…ƒç´ åˆ†åˆ«èµ‹å€¼ç»™x1,y1,x2,y2
                    if save_txt:  # Write to file,å¦‚æœsave_txtä¸ºTrueï¼Œåˆ™å°†é¢„æµ‹æ¡†çš„åæ ‡å’Œç±»åˆ«å†™å…¥txtæ–‡ä»¶ä¸­
                        xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(
                            -1).tolist()  # normalized xywh,å°†é¢„æµ‹æ¡†çš„åæ ‡ä»åŸå§‹åæ ‡è½¬æ¢ä¸ºå½’ä¸€åŒ–åæ ‡
                        line = (cls, *xywh, conf) if save_conf else (
                            cls, *xywh)  # label format,å¦‚æœsave_confä¸ºTrueï¼Œåˆ™å°†ç½®ä¿¡åº¦ä¹Ÿå†™å…¥txtæ–‡ä»¶ä¸­
                        with open(f'{txt_path}.txt', 'a') as f:  # æ‰“å¼€txtæ–‡ä»¶,'a'è¡¨ç¤ºè¿½åŠ 
                            f.write(('%g ' * len(line)).rstrip() % line + '\n')  # å†™å…¥txtæ–‡ä»¶

                    if save_img or save_crop or view_img:  # Add bbox to image,å¦‚æœsave_imgä¸ºTrueï¼Œåˆ™å°†é¢„æµ‹æ¡†å’Œæ ‡ç­¾ç»˜åˆ¶åœ¨å›¾ç‰‡ä¸Š
                        c = int(cls)  # integer class,è·å–ç±»åˆ«
                        label = None if hide_labels else (names[
                                                              c] if hide_conf else f'{names[c]} {conf:.2f}')  # å¦‚æœhide_labelsä¸ºTrueï¼Œåˆ™ä¸æ˜¾ç¤ºæ ‡ç­¾ï¼Œå¦åˆ™æ˜¾ç¤ºæ ‡ç­¾ï¼Œå¦‚æœhide_confä¸ºTrueï¼Œåˆ™ä¸æ˜¾ç¤ºç½®ä¿¡åº¦ï¼Œå¦åˆ™æ˜¾ç¤ºç½®ä¿¡åº¦
                        annotator.box_label(xyxy, label, color=colors(c, True))  # ç»˜åˆ¶é¢„æµ‹æ¡†å’Œæ ‡ç­¾




            # Stream results,åœ¨å›¾ç‰‡ä¸Šç»˜åˆ¶é¢„æµ‹æ¡†å’Œæ ‡ç­¾å±•ç¤º
            im0 = annotator.result()  # è·å–ç»˜åˆ¶é¢„æµ‹æ¡†å’Œæ ‡ç­¾çš„å›¾ç‰‡
            if view_img:  # å¦‚æœview_imgä¸ºTrueï¼Œåˆ™å±•ç¤ºå›¾ç‰‡
                if platform.system() == 'Linux' and p not in windows:  # å¦‚æœç³»ç»Ÿä¸ºLinuxï¼Œä¸”pä¸åœ¨windowsä¸­
                    windows.append(p)  # å°†pæ·»åŠ åˆ°windowsä¸­
                    cv2.namedWindow(str(p),
                                    cv2.WINDOW_NORMAL | cv2.WINDOW_KEEPRATIO)  # allow window resize (Linux),å…è®¸çª—å£è°ƒæ•´å¤§å°,WINDOW_NORMALè¡¨ç¤ºç”¨æˆ·å¯ä»¥è°ƒæ•´çª—å£å¤§å°ï¼ŒWINDOW_KEEPRATIOè¡¨ç¤ºçª—å£å¤§å°ä¸å˜
                    cv2.resizeWindow(str(p), im0.shape[1], im0.shape[0])  # è°ƒæ•´çª—å£å¤§å°ï¼Œä½¿å…¶ä¸å›¾ç‰‡å¤§å°ä¸€è‡´
                cv2.imshow(str(p), im0)  # æ˜¾ç¤ºå›¾ç‰‡
                cv2.waitKey(1)  # 1 millisecond                                        #ç­‰å¾…1æ¯«ç§’

            # Save results (image with detections)
            if save_img:  # å¦‚æœsave_imgä¸ºTrueï¼Œåˆ™ä¿å­˜å›¾ç‰‡
                if dataset.mode == 'image':  # å¦‚æœæ•°æ®é›†æ¨¡å¼ä¸ºimage
                    cv2.imwrite(save_path, im0)  # ä¿å­˜å›¾ç‰‡
                else:  # 'video' or 'stream'ï¼Œå¦‚æœæ•°æ®é›†æ¨¡å¼ä¸ºvideoæˆ–stream
                    if vid_path[i] != save_path:  # new videoï¼Œå¦‚æœvid_path[i]ä¸ç­‰äºsave_path
                        vid_path[i] = save_path  # å°†save_pathèµ‹å€¼ç»™vid_path[i]
                        if isinstance(vid_writer[i], cv2.VideoWriter):  # å¦‚æœvid_writer[i]æ˜¯cv2.VideoWriterç±»å‹
                            vid_writer[i].release()  # release previous video writer
                        if vid_cap:  # video
                            fps = vid_cap.get(cv2.CAP_PROP_FPS)  # è·å–è§†é¢‘çš„å¸§ç‡
                            w = int(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH))  # è·å–è§†é¢‘çš„å®½åº¦
                            h = int(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))  # è·å–è§†é¢‘çš„é«˜åº¦
                        else:  # stream
                            fps, w, h = 30, im0.shape[1], im0.shape[0]
                        save_path = str(Path(save_path).with_suffix('.mp4'))  # force *.mp4 suffix on results videos
                        vid_writer[i] = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))
                    vid_writer[i].write(im0)

    if save_txt or save_img:
        s = f"\n{len(list(save_dir.glob('labels/*.txt')))} labels saved to {save_dir / 'labels'}" if save_txt else ''  # å¦‚æœsave_txtä¸ºTrueï¼Œåˆ™æ‰“å°ä¿å­˜çš„æ ‡ç­¾æ•°é‡
        LOGGER.info(f"Results saved to {colorstr('bold', save_dir)}{s}")  # æ‰“å°ä¿å­˜çš„è·¯å¾„
    if update:
        strip_optimizer(
            weights[0])  # update model (to fix SourceChangeWarning)                                      #æ›´æ–°æ¨¡å‹


"""
    weights: ç”¨äºæ£€æµ‹çš„æ¨¡å‹è·¯å¾„
    source: æ£€æµ‹çš„è·¯å¾„ï¼Œå¯ä»¥æ˜¯å›¾ç‰‡ï¼Œè§†é¢‘ï¼Œæ–‡ä»¶å¤¹ï¼Œä¹Ÿå¯ä»¥æ˜¯æ‘„åƒå¤´ï¼ˆâ€˜0â€™ï¼‰
    data: æ•°æ®é›†çš„é…ç½®æ–‡ä»¶ï¼Œç”¨äºè·å–ç±»åˆ«åç§°ï¼Œå’Œè®­ç»ƒæ—¶çš„ä¸€æ ·
    imgsz: ç½‘ç»œè¾“å…¥çš„å›¾ç‰‡å¤§å°ï¼Œé»˜è®¤ä¸º640
    conf-thres: ç½®ä¿¡åº¦é˜ˆå€¼ï¼Œå¤§äºè¯¥é˜ˆå€¼çš„æ¡†æ‰ä¼šè¢«ä¿ç•™
    iou-thres: NMSçš„é˜ˆå€¼ï¼Œå¤§äºè¯¥é˜ˆå€¼çš„æ¡†ä¼šè¢«åˆå¹¶ï¼Œå°äºè¯¥é˜ˆå€¼çš„æ¡†ä¼šè¢«ä¿ç•™ï¼Œä¸€èˆ¬è®¾ç½®ä¸º0.45
    max-det: æ¯å¼ å›¾ç‰‡æœ€å¤šæ£€æµ‹çš„ç›®æ ‡æ•°ï¼Œé»˜è®¤ä¸º1000
    device: æ£€æµ‹çš„è®¾å¤‡ï¼Œå¯ä»¥æ˜¯cpuï¼Œä¹Ÿå¯ä»¥æ˜¯gpuï¼Œå¯ä»¥ä¸ç”¨è®¾ç½®ï¼Œä¼šè‡ªåŠ¨é€‰æ‹©
    view-img: æ˜¯å¦æ˜¾ç¤ºæ£€æµ‹ç»“æœï¼Œé»˜è®¤ä¸ºFalse
    save-txt: æ˜¯å¦å°†æ£€æµ‹ç»“æœä¿å­˜ä¸ºtxtæ–‡ä»¶ï¼ŒåŒ…æ‹¬ç±»åˆ«ï¼Œæ¡†çš„åæ ‡ï¼Œé»˜è®¤ä¸ºFalse
    save-conf: æ˜¯å¦å°†æ£€æµ‹ç»“æœä¿å­˜ä¸ºtxtæ–‡ä»¶ï¼ŒåŒ…æ‹¬ç±»åˆ«ï¼Œæ¡†çš„åæ ‡ï¼Œç½®ä¿¡åº¦ï¼Œé»˜è®¤ä¸ºFalse
    save-crop: æ˜¯å¦ä¿å­˜è£å‰ªé¢„æµ‹æ¡†çš„å›¾ç‰‡ï¼Œé»˜è®¤ä¸ºFalse
    nosave: ä¸ä¿å­˜æ£€æµ‹ç»“æœï¼Œé»˜è®¤ä¸ºFalse
    classes: æ£€æµ‹çš„ç±»åˆ«ï¼Œé»˜è®¤ä¸ºNoneï¼Œå³æ£€æµ‹æ‰€æœ‰ç±»åˆ«ï¼Œå¦‚æœè®¾ç½®äº†è¯¥å‚æ•°ï¼Œåˆ™åªæ£€æµ‹è¯¥å‚æ•°æŒ‡å®šçš„ç±»åˆ«
    agnostic-nms: è¿›è¡ŒNMSå»é™¤ä¸åŒç±»åˆ«ä¹‹é—´çš„æ¡†ï¼Œé»˜è®¤ä¸ºFalse
    augment: æ¨ç†æ—¶æ˜¯å¦è¿›è¡ŒTTAæ•°æ®å¢å¼ºï¼Œé»˜è®¤ä¸ºFalse
    update: æ˜¯å¦æ›´æ–°æ¨¡å‹ï¼Œé»˜è®¤ä¸ºFalse,å¦‚æœè®¾ç½®ä¸ºTrueï¼Œåˆ™ä¼šæ›´æ–°æ¨¡å‹,å¯¹æ¨¡å‹è¿›è¡Œå‰ªæï¼Œå»é™¤ä¸å¿…è¦çš„å‚æ•°
    project: æ£€æµ‹ç»“æœä¿å­˜çš„æ–‡ä»¶å¤¹ï¼Œé»˜è®¤ä¸ºruns/detect
    name: æ£€æµ‹ç»“æœä¿å­˜çš„æ–‡ä»¶å¤¹ï¼Œé»˜è®¤ä¸ºexp
    exist-ok: å¦‚æœæ£€æµ‹ç»“æœä¿å­˜çš„æ–‡ä»¶å¤¹å·²ç»å­˜åœ¨ï¼Œæ˜¯å¦è¦†ç›–ï¼Œé»˜è®¤ä¸ºFalse
    line-thickness: æ¡†çš„çº¿å®½ï¼Œé»˜è®¤ä¸º3
    hide-labels: æ˜¯å¦éšè—ç±»åˆ«ï¼Œé»˜è®¤ä¸ºFalse
    hide-conf: æ˜¯å¦éšè—ç½®ä¿¡åº¦ï¼Œé»˜è®¤ä¸ºFalse
    half: æ˜¯å¦ä½¿ç”¨åŠç²¾åº¦æ¨ç†ï¼Œé»˜è®¤ä¸ºFalse
    dnn: æ˜¯å¦ä½¿ç”¨OpenCVçš„DNNæ¨¡å—è¿›è¡Œæ¨ç†ï¼Œé»˜è®¤ä¸ºFalse
    vid-stride: è§†é¢‘å¸§é‡‡æ ·é—´éš”ï¼Œé»˜è®¤ä¸º1ï¼Œå³æ¯ä¸€å¸§éƒ½è¿›è¡Œæ£€æµ‹
"""


def main(opt):  # ä¸»å‡½æ•°  ä½œä¸ºåŒ…è°ƒç”¨æ—¶ï¼Œè°ƒç”¨ main({'weights':'xxx','source':'xxx'})
    check_requirements(exclude=('tensorboard', 'thop'))  # æ£€æŸ¥ä¾èµ–ï¼Œå¦‚æœæ²¡æœ‰å®‰è£…ä¾èµ–ï¼Œåˆ™ä¼šè‡ªåŠ¨å®‰è£…
    run(**vars(opt))  # è¿è¡Œç¨‹åºï¼Œvars()å‡½æ•°è¿”å›å¯¹è±¡objectçš„å±æ€§å’Œå±æ€§å€¼çš„å­—å…¸å¯¹è±¡
